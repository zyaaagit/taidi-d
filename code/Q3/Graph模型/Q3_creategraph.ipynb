{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from py2neo import Graph, Node, Relationship, NodeMatcher\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblist_path = '../../../demo3/Q3_jobList.xlsx'\n",
    "resume_path = '../../../demo3/Q3_resume.xlsx'\n",
    "\n",
    "resume_duplicate = '../../../demo3/resume_duplicate.xlsx'\n",
    "resume_duplicate_id = '../../../demo3/重复简历.csv'\n",
    "\n",
    "resume_type = {'id':str,'age':str,'edutime_days':str,'worktime_days':str,'traintime_days':str,'projecttime_days':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    special_txt = r'\\[|\\]|【|】|\\'|\"|“|”|\\\\t'\n",
    "    data.replace(special_txt,'', regex=True, inplace=True)\n",
    "    data.replace('无','', inplace=True)\n",
    "    data.replace('未填写','', inplace=True)\n",
    "    data.replace(np.nan,'', inplace=True)\n",
    "    data.replace('无,无,无','', inplace=True)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_inf = pd.read_excel(resume_path, dtype = resume_type)\n",
    "resume_inf['id'] = resume_inf['id'].apply(lambda x:x.strip()) # 在jupyter上，\\t不一定代表制表符，也有可能是字符串\n",
    "# 将NaN替换为''\n",
    "resume_inf = resume_inf.replace(np.nan,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skill = set()\n",
    "for i in resume_inf['skill_info']:\n",
    "    for j in i.split(','):\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            resume_skill.add(j.split(':')[0])\n",
    "resume_skill = list(resume_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_skill(x):\n",
    "    result_list = []\n",
    "    for i in x.split(','):\n",
    "        j = i.split(':')[0]\n",
    "        if j:\n",
    "            index = resume_skill.index(j) if j in resume_skill else -1\n",
    "            result_list.append((j, index))\n",
    "    result_list.sort(key=lambda x: x[1])\n",
    "    sorted_result = [item[0] for item in sorted(result_list, key=lambda x: x[1])]\n",
    "    return str(sorted_result)\n",
    "\n",
    "resume_inf['skill'] = resume_inf['skill_info'].apply(sort_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_inf['cert_info_cert'] =  resume_inf['cert_info'].apply(lambda x: x.split(':')[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算重复样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去重复样本\n",
    "resume_columns = resume_inf.columns.to_list()\n",
    "for i in ['concatenated','cert_info', 'birthday' ,'age','skill_info']:\n",
    "    resume_columns.remove(i)\n",
    "duplicates = resume_inf.duplicated(subset=resume_columns[3:], keep=False)\n",
    "duplicates.value_counts()\n",
    "resume_inf_d = resume_inf.drop_duplicates(subset=resume_columns[3:], keep='first')\n",
    "resume_inf_d = resume_inf_d.reset_index()\n",
    "resume_inf_d = resume_inf_d.drop(columns=['level_0','skill','cert_info_cert'])\n",
    "resume_inf_d.to_excel(resume_duplicate,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = resume_inf[resume_inf.duplicated(subset=resume_columns[3:], keep=False)]\n",
    "duplicate_groups = duplicate_rows.groupby(by=resume_columns[3:])\n",
    "\n",
    "a = 0\n",
    "resume_duplicates = pd.DataFrame(columns = ['重复样本','其它重复样本'])\n",
    "\n",
    "for key, value in duplicate_groups:\n",
    "    resume_duplicates.loc[a,'重复样本'] = str(value['id'].tolist()[0])\n",
    "    resume_duplicates.loc[a,'其它重复样本'] = str(value['id'].tolist()[1:])\n",
    "    a += 1\n",
    "resume_duplicates = clean_data(resume_duplicates)\n",
    "resume_duplicates['重复样本'] = resume_duplicates['重复样本'].apply(lambda x:x.strip()) # 在jupyter上，\\t不一定代表制表符，也有可能是字符串\n",
    "resume_duplicates.to_csv(resume_duplicate_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "制作知识图谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接neo4j数据库，输入地址、用户名、密码\n",
    "graph = Graph('http://localhost:7474/',auth = ('neo4j','Xysan955.'))\n",
    "graph.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义字符串\n",
    "#短字段，只有一个文本\n",
    "resume_singleword = ['id', 'username',  'address', 'province', 'county', 'region','sex','job_wanted_status', 'arrivalTime',\n",
    "                       'birthday','exp', 'political','workNature', 'willSalaryStart', 'willSalaryEnd', \n",
    "                       'worktime_days','projecttime_days', 'traintime_days', 'edutime_days', \n",
    "                       'is_graduate']\n",
    "resume_singleword_ch = ['ID', '用户名', '地址', '省', '市', '区', '性别', '求职状态', '上岗时间', '生日', '经验', '政治面貌', '工作性质', '最低薪资', '最高薪资', '工作时间', '项目时间', '训练时间', '教育时间', '应届身份']\n",
    "resume_singleword_relation = ['ID', '用户名', '居住地', '期望省', '期望市', '期望区', '性别', '求职状态','上岗时间', '生日', '经验', '政治面貌', '是否兼职', '期望最低薪资', '期望最高薪资', '工作时间', '项目时间', '训练时间', '教育时间', '是否应届']\n",
    "\n",
    "#短字段，有多个文本，通过','相隔\n",
    "resume_multiword = ['expectPosition','expectIndustry',\n",
    "                      'workEp_companies','workEp_industries','workEp_positionNames',\n",
    "                      'projectEP_companies','projectEP_projectNames','projectEP_roleNames',\n",
    "                      'trainEp_orgName', 'trainEP_recordName',\n",
    "                      'eduEp_educationBackgrounds','eduEP_schools', 'eduEP_specialities']\n",
    "resume_multiword_ch = ['岗位', '行业', '公司', '行业', '岗位', '公司', '项目名称', '项目人员', '公司', '培训项目', '学历', '学校', '专业']\n",
    "resume_multiword_relation = ['期望岗位', '期望行业', '原单元', '原单位行业', '原单位岗位', '项目所属公司', '项目名称', '项目身份', '培训机构', '培训项目', '教育背景', '学校', '专业']\n",
    "\n",
    "#技能，用键值对构成，通过','相隔\n",
    "resume_skill = ['com_info', 'cert_info', 'lang_info', 'skill_info', 'keyword_info']\n",
    "resume_skill_ch = ['竞赛情况', '证书情况', '语言情况', '技能', '关键词情况']\n",
    "resume_skill_relation = ['竞赛情况', '证书情况', '语言情况', '技能情况', '关键词情况']\n",
    "\n",
    "#长字段，主要是关键词，通过','相隔\n",
    "resume_keyword = ['selfEvaluation_keywords','workEP_descriptions_keywords','projectEp_descriptions_keywords','projectEP_achievements_keywords','trainEP_description_keywords']\n",
    "resume_keyword_ch = ['自我评价关键词', '工作描述关键词', '项目描述关键词', '项目成就关键词', '培训描述关键词']\n",
    "resume_keyword_relation = ['自我评价', '工作描述', '项目描述', '项目成就', '培训描述']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建单个点\n",
    "def single_node(data, column_ch, column_relation, node_id):\n",
    "    node_sigleword = NodeMatcher(graph).match(name=str(data)).first()\n",
    "\n",
    "    # 判断是否存在节点，如果存在包含该标签的节点，则跳过，如果存在节点但不包含标签，则增加标签，如果不存在节点，则创建\n",
    "    if node_sigleword == None:\n",
    "        node_sigleword = Node(column_ch, name = str(data))\n",
    "        graph.create(node_sigleword)\n",
    "    elif column_ch in node_sigleword.labels:\n",
    "        pass\n",
    "    else:\n",
    "        node_sigleword.add_label(column_ch)\n",
    "        graph.push(node_sigleword)\n",
    "\n",
    "    # 创建关系时，如果是Id则跳过\n",
    "    if column_ch == 'ID':\n",
    "        pass\n",
    "    else:\n",
    "        create_relation(node_id, node_sigleword, column_relation)\n",
    "\n",
    "# 创建技能点\n",
    "def skill_node(data,column_ch, column_relation, node_id):\n",
    "    data = data.split(',')\n",
    "    data_skill = [skill.split(':')[0] for skill in data]\n",
    "    for i in data_skill:\n",
    "        node_skill = NodeMatcher(graph).match(name=str(i)).first()\n",
    "        if node_skill == None:\n",
    "            node_skill = Node(column_ch, name = str(i))\n",
    "            graph.create(node_skill)\n",
    "        elif column_ch in node_skill.labels:\n",
    "            pass\n",
    "        else:\n",
    "            node_skill.add_label(column_ch)\n",
    "            graph.push(node_skill)\n",
    "        create_relation(node_id, node_skill, column_relation)\n",
    "\n",
    "# 创建关键字节点\n",
    "def word_split_node(data, column_ch, column_relation, node_id):\n",
    "    data = data.split(',')\n",
    "    # 分割json格式\n",
    "    for i in data:\n",
    "        node_keyword = NodeMatcher(graph).match(name=str(i)).first()\n",
    "        if node_keyword == None:\n",
    "            node_keyword = Node(column_ch, name = str(i))\n",
    "            graph.create(node_keyword)\n",
    "        elif column_ch in node_keyword.labels:\n",
    "            pass\n",
    "        else:\n",
    "            node_keyword.add_label(column_ch)\n",
    "            graph.push(node_keyword)\n",
    "        create_relation(node_id, node_keyword, column_relation) \n",
    "\n",
    "#创建id和其它关系的连接\n",
    "def create_relation(node_id, node, column_relation):\n",
    "    relation = Relationship(node_id,column_relation,node)\n",
    "    graph.create(relation)\n",
    "\n",
    "def create_node(data, columns, columns_ch, column_relation, type):\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(len(columns)):\n",
    "            if data.loc[i,columns[j]] == '':\n",
    "                continue\n",
    "            else:\n",
    "                id = data.loc[i,'id']\n",
    "                node_id = NodeMatcher(graph).match(name=str(id)).first()\n",
    "                if type == 'single':\n",
    "                    single_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "                elif type == 'splitword':\n",
    "                    word_split_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "                elif type == 'skill':\n",
    "                    skill_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "\n",
    "def main():\n",
    "    create_node(resume_inf_d, resume_singleword, resume_singleword_ch, resume_singleword_relation, 'single')\n",
    "    create_node(resume_inf_d, resume_multiword, resume_multiword_ch, resume_multiword_relation, 'splitword')\n",
    "    create_node(resume_inf_d, resume_keyword, resume_keyword_ch, resume_keyword_relation, 'splitword')\n",
    "    create_node(resume_inf_d, resume_skill, resume_skill_ch, resume_skill_relation, 'skill')\n",
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建joblist的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblist_inf = pd.read_excel(joblist_path, dtype = {'id':str})\n",
    "\n",
    "# 数据清洗\n",
    "joblist_inf['deadline'] = joblist_inf['deadline'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.isna(x) != True else x)\n",
    "joblist_inf['id'] = joblist_inf['id'].apply(lambda x:x.strip()) # 在jupyter上，\\t不一定代表制表符，也有可能是字符串\n",
    "# 将NaN替换为''\n",
    "joblist_inf = joblist_inf.replace(np.nan,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义字符串\n",
    "joblist_singleword = ['id', 'enterpriseName', 'positionName', 'willNature', 'minimumWage','maximumWage', 'payMethod', 'exp', 'edu_require', \n",
    "                       'position_count', 'workplace', 'provinceCode', 'cityCode', 'regionCode','enter_address', 'fixed_province', \n",
    "                       'fixed_city', 'fixed_region','deadline','eA_shortName', 'eA_econKind', 'job_personScope','job_registCapi', 'job_email', 'job_phone']\n",
    "                       \n",
    "joblist_singleword_ch = ['ID', '公司', '岗位', '工作性质',  '最低薪资', '最高薪资', '支付方式', '经验', '学历', '人数', '地址', '地理编码', \n",
    "                          '地理编码', '地理编码', '地址', '省', '市', '区', '截止时间','缩写', '公司性质', '人数' , '资本', '邮箱', '电话']\n",
    "\n",
    "joblist_singleword_relation = ['ID', '公司', '岗位', '工作性质',  '最低薪资', '最高薪资', '支付方式', '经验要求', '学历要求', '人数', \n",
    "                                '工作地点', '省级编码', '市级编码', '区级编码', '具体工作地点', '省', '市', '区', '岗位截止时间', \n",
    "                                '公司缩写', '公司性质', '公司人数' , '公司注册资本', '公司邮箱', '公司电话']\n",
    "\n",
    "joblist_multiword = ['function', 'keyword_info','skill_info','job_industry', 'welfare']\n",
    "joblist_multiword_ch = ['职责', '关键词', '技能要求', '行业', '福利']\n",
    "joblist_multiword_relation = ['职责要求', '岗位关键词', '技能要求', '公司行业', '福利待遇']\n",
    "\n",
    "joblist_keyword = ['jobRequiredments_keywords']\n",
    "joblist_keyword_ch = ['关键词']\n",
    "joblist_keyword_relation = ['工作要求']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建单个点\n",
    "def single_node(data, column_ch, column_relation, node_id):\n",
    "    node_sigleword = NodeMatcher(graph).match(name=str(data)).first()\n",
    "    if node_sigleword == None:\n",
    "        node_sigleword = Node(column_ch, name = str(data))\n",
    "        graph.create(node_sigleword)\n",
    "    elif column_ch in node_sigleword.labels:\n",
    "        pass\n",
    "    else:\n",
    "        node_sigleword.add_label(column_ch)\n",
    "        graph.push(node_sigleword)\n",
    "    \n",
    "    if column_ch == 'ID':\n",
    "        pass\n",
    "    else:\n",
    "        create_relation(node_id, node_sigleword, column_relation)\n",
    "\n",
    "# 创建技能点\n",
    "def skill_node(data,column_ch, column_relation, node_id):\n",
    "    data = data.split(',')\n",
    "    data_skill = [skill.split(':')[0] for skill in data]\n",
    "    for i in data_skill:\n",
    "        node_skill = NodeMatcher(graph).match(name=str(i)).first()\n",
    "        if node_skill == None:\n",
    "            node_skill = Node(column_ch, name = str(i))\n",
    "            graph.create(node_skill)\n",
    "        elif column_ch in node_skill.labels:\n",
    "            pass\n",
    "        else:\n",
    "            node_skill.add_label(column_ch)\n",
    "            graph.push(node_skill)\n",
    "        create_relation(node_id, node_skill, column_relation)\n",
    "\n",
    "# 创建关键字节点\n",
    "def word_split_node(data, column_ch, column_relation, node_id):\n",
    "    data = data.split(',')\n",
    "    # 分割json格式\n",
    "    for i in data:\n",
    "        node_keyword = NodeMatcher(graph).match(name=str(i)).first()\n",
    "        if node_keyword == None:\n",
    "            node_keyword = Node(column_ch, name = str(i))\n",
    "            graph.create(node_keyword)\n",
    "        elif column_ch in node_keyword.labels:\n",
    "            pass\n",
    "        else:\n",
    "            node_keyword.add_label(column_ch)\n",
    "            graph.push(node_keyword)\n",
    "        create_relation(node_id, node_keyword, column_relation) \n",
    "\n",
    "#创建id和其它关系的连接\n",
    "def create_relation(node_id, node, column_relation):\n",
    "    relation = Relationship(node_id,column_relation,node)\n",
    "    graph.create(relation)\n",
    "\n",
    "def create_node(data, columns, columns_ch, column_relation, type):\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(len(columns)):\n",
    "            if data.loc[i,columns[j]] == '':\n",
    "                continue\n",
    "            else:\n",
    "                id = data.loc[i,'id']\n",
    "                node_id = NodeMatcher(graph).match(name=str(id)).first()\n",
    "                if type == 'single':\n",
    "                    single_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "                elif type == 'splitword':\n",
    "                    word_split_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "                elif type == 'skill':\n",
    "                    skill_node(data.loc[i, columns[j]], columns_ch[j], column_relation[j],node_id)\n",
    "\n",
    "def main():\n",
    "    create_node(joblist_inf, joblist_singleword, joblist_singleword_ch, joblist_singleword_relation, 'single')\n",
    "    create_node(joblist_inf, joblist_multiword, joblist_multiword_ch, joblist_multiword_relation, 'splitword')\n",
    "    create_node(joblist_inf, joblist_keyword, joblist_keyword_ch, joblist_keyword_relation, 'splitword')\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
